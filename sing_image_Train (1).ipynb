{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThNYY7P40PwY"
      },
      "source": [
        "# task image classifier for itsaaz  company "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RKout6ML0Jup"
      },
      "outputs": [],
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt \n",
        "import os \n",
        "import pathlib "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CG7KV7c74dyh"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E3m-dDn94NK6"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/data.zip'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "f6aS29G-5Bna"
      },
      "outputs": [],
      "source": [
        "directory='/content/data'\n",
        "train_dir=pathlib.Path(directory)\n",
        "ClassName=np.array([item.name for item in train_dir.glob('*')])\n",
        "Full_dataset=tf.data.Dataset.list_files(str(train_dir/'*/*')) # All image training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REQ_CnV5iiGw",
        "outputId": "1465c50f-839c-4028-dafa-f8060b7007e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['croped', 'sign', 'False', 'stamp'], dtype='<U6')"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ClassName"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HPcyUq8NcIiL"
      },
      "outputs": [],
      "source": [
        "validation_split=0.1\n",
        "Dataset_size=len(list(Full_dataset))\n",
        "train_size=int((1-validation_split)*Dataset_size)\n",
        "train_dataset=Full_dataset.take(train_size)\n",
        "validation_dataset=Full_dataset.skip(train_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnIShsmpDLbK"
      },
      "source": [
        "##  * preprocess data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cphCAo888W5Q"
      },
      "source": [
        "# create helper function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "EEZn76qi8cCs"
      },
      "outputs": [],
      "source": [
        "def augment_data(image):\n",
        "  image=tf.image.resize_with_crop_or_pad(image,180,180)\n",
        "  image=tf.image.random_crop(image,size=[150,150,3])\n",
        "  image=tf.image.random_brightness(image,max_delta=0.5)\n",
        "  return image\n",
        "\n",
        "def get_label(file_path):\n",
        "  parts=tf.strings.split(file_path,os.path.sep)\n",
        "  return parts[-2]==ClassName\n",
        "\n",
        "def load_image(image_path):\n",
        "  image=tf.io.read_file(image_path)\n",
        "  image=tf.image.decode_jpeg(image,3)\n",
        "  image=tf.cast(image,tf.float32)\n",
        "  return image \n",
        "\n",
        "def normalize(image):\n",
        "  image=(image/127.5)-1\n",
        "  return image \n",
        "\n",
        "def resize(image,height,width):\n",
        "  image=tf.image.resize(image,(height,width),method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  return image "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIJM8bnaABAV"
      },
      "source": [
        "# creat base function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "MVVLgzr8BX14"
      },
      "outputs": [],
      "source": [
        "def load_image_with_label(image_path):\n",
        "  label=get_label(image_path)\n",
        "  img=load_image(image_path)\n",
        "  return img,label\n",
        "\n",
        "def load_image_train(image_file):\n",
        "  image,label=load_image_with_label(image_file)\n",
        "  image=augment_data(image)\n",
        "  image=normalize(image)\n",
        "  return image,label\n",
        "\n",
        "def load_image_test(image_file):\n",
        "  image,label=load_image_with_label(image_file)\n",
        "  image=resize(image,150,150)\n",
        "  image=normalize(image)\n",
        "  return image,label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVVy_yZgB3Uu"
      },
      "source": [
        "# create pipeline dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Yiu7QEegCUXd"
      },
      "outputs": [],
      "source": [
        "train_dataset=train_dataset.map(load_image_train)\n",
        "train_dataset=train_dataset.shuffle(1000)\n",
        "train_dataset=train_dataset.batch(32)\n",
        "\n",
        "validation_dataset=validation_dataset.map(load_image_test)\n",
        "validation_dataset=validation_dataset.batch(32)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTi660_2DRVh"
      },
      "source": [
        "## * creat model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgSPwHc_DY-y"
      },
      "source": [
        "ما در این پروزه به دلیل این که تعداد داده های محدودی برای کلاس بندی داریم مجبور هستیم از شبکه های از پیش اموزش دیده استفاده کنیم "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ytz75bBvEDcK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.layers import Dense,Dropout,BatchNormalization,Flatten,Input\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sUUVKA1FIx_"
      },
      "source": [
        "# creat model with API function "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7-MMUQgEtiw",
        "outputId": "9aa5f9ad-7a74-4105-bee9-ee2ef9d9c490"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_Conv=VGG16(weights='imagenet',include_top=False,input_tensor=Input(shape=(150,150,3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "yWbuw8yuGMBC"
      },
      "outputs": [],
      "source": [
        "base_Conv.trainable=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "VJSchHhcHQUm"
      },
      "outputs": [],
      "source": [
        "inputs=base_Conv.output\n",
        "layer=Flatten()(inputs)\n",
        "layer=Dense(512,activation='relu')(layer)\n",
        "layer=BatchNormalization()(layer)\n",
        "layer=Dropout(rate=0.25)(layer)\n",
        "layer=Dense(128,activation='relu')(layer)\n",
        "layer=Dropout(rate=0.25)(layer)\n",
        "output=Dense(4,activation='softmax')(layer)\n",
        "\n",
        "model=Model(base_Conv.input,output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "kB2JJBiRI7J5"
      },
      "outputs": [],
      "source": [
        "model.compile(loss=CategoricalCrossentropy(),optimizer='adam',metrics=['acc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMCPWrGCeFWu"
      },
      "source": [
        "creat checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IQ9e_efKeeJT"
      },
      "outputs": [],
      "source": [
        "file_path='/content/my_model.h5'\n",
        "checkpoint=tf.keras.callbacks.ModelCheckpoint(\n",
        "                    file_path,\n",
        "                    monitor='val_loss',\n",
        "                    save_best_only=True)\n",
        "callback_list=[checkpoint]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4jRriWjI7th",
        "outputId": "b08a8233-4d32-415d-998e-0d425e55db5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "9/9 [==============================] - 11s 249ms/step - loss: 1.3697 - acc: 0.5017 - val_loss: 1.2082 - val_acc: 0.5312\n",
            "Epoch 2/15\n",
            "9/9 [==============================] - 9s 144ms/step - loss: 0.7247 - acc: 0.7387 - val_loss: 1.5473 - val_acc: 0.4375\n",
            "Epoch 3/15\n",
            "9/9 [==============================] - 9s 140ms/step - loss: 0.4663 - acc: 0.8258 - val_loss: 1.6930 - val_acc: 0.5625\n",
            "Epoch 4/15\n",
            "9/9 [==============================] - 11s 207ms/step - loss: 0.4460 - acc: 0.8397 - val_loss: 1.2714 - val_acc: 0.6562\n",
            "Epoch 5/15\n",
            "9/9 [==============================] - 9s 149ms/step - loss: 0.3292 - acc: 0.8955 - val_loss: 1.9570 - val_acc: 0.4062\n",
            "Epoch 6/15\n",
            "9/9 [==============================] - 9s 139ms/step - loss: 0.2919 - acc: 0.8885 - val_loss: 1.8717 - val_acc: 0.5938\n",
            "Epoch 7/15\n",
            "9/9 [==============================] - 9s 154ms/step - loss: 0.2367 - acc: 0.9233 - val_loss: 1.6285 - val_acc: 0.5938\n",
            "Epoch 8/15\n",
            "9/9 [==============================] - 9s 142ms/step - loss: 0.2200 - acc: 0.9268 - val_loss: 1.4784 - val_acc: 0.5625\n",
            "Epoch 9/15\n",
            "9/9 [==============================] - 9s 138ms/step - loss: 0.2012 - acc: 0.9512 - val_loss: 1.2341 - val_acc: 0.6875\n",
            "Epoch 10/15\n",
            "9/9 [==============================] - 10s 142ms/step - loss: 0.1496 - acc: 0.9477 - val_loss: 1.8032 - val_acc: 0.6250\n",
            "Epoch 11/15\n",
            "9/9 [==============================] - 9s 148ms/step - loss: 0.1404 - acc: 0.9617 - val_loss: 1.5528 - val_acc: 0.5938\n",
            "Epoch 12/15\n",
            "9/9 [==============================] - 9s 136ms/step - loss: 0.1373 - acc: 0.9547 - val_loss: 1.2139 - val_acc: 0.7188\n",
            "Epoch 13/15\n",
            "9/9 [==============================] - 9s 130ms/step - loss: 0.1611 - acc: 0.9477 - val_loss: 1.7404 - val_acc: 0.5625\n",
            "Epoch 14/15\n",
            "9/9 [==============================] - 9s 138ms/step - loss: 0.1137 - acc: 0.9756 - val_loss: 1.4042 - val_acc: 0.6562\n",
            "Epoch 15/15\n",
            "9/9 [==============================] - 9s 151ms/step - loss: 0.1465 - acc: 0.9512 - val_loss: 2.9603 - val_acc: 0.5312\n"
          ]
        }
      ],
      "source": [
        "hi=model.fit(train_dataset,epochs=15,validation_data=validation_dataset,\n",
        "             callbacks=callback_list)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "sing_image_Train.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "vscode": {
      "interpreter": {
        "hash": "1bff919847c3523a817a19ca9edec7c337a9c984497377a8255cd61217aa9bf0"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
